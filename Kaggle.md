视频课程
---
[How to Win a Data Science Competition: Learn from Top Kagglers](https://www.coursera.org/learn/competitive-data-science/home/welcome)

Blog
---
https://machinelearningmastery.com/blog/

Overview of methods  
---
[Scikit-Learn (or sklearn) library](http://scikit-learn.org/stable/)   
[Overview of k-NN](http://scikit-learn.org/stable/modules/neighbors.html)(sklearn's documentation)  
[Overview of Linear Models](http://scikit-learn.org/stable/modules/linear_model.html)(sklearn's documentation)  
[Overview of Decision Trees](http://scikit-learn.org/stable/modules/tree.html)(sklearn's documentation)  
[Decision Tree](https://en.wikipedia.org/wiki/Decision_tree_learning)(Wiki)  
Overview of algorithms and parameters in [H2O documentation](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science.html)    

Additional Tools  
---
[Vowpal Wabbit](https://github.com/JohnLangford/vowpal_wabbit) repository  
[XGBoost](https://github.com/dmlc/xgboost) repository  
[LightGBM](https://github.com/Microsoft/LightGBM) repository  
[Interactive demo](http://playground.tensorflow.org/) of simple feed-forward Neural Net  
Frameworks for Neural Nets: [Keras](https://keras.io/),[PyTorch](http://pytorch.org/),[TensorFlow](https://www.tensorflow.org/),[MXNet](http://mxnet.io/),[Lasagne](https://lasagne.readthedocs.io/en/latest/)  
[Example from sklearn with different decision surfaces](http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html)  
[Arbitrary order factorization machines](https://github.com/geffy/tffm)  

knowledge of basic ML algorithms
---
[Explanation of Random Forest](https://www.datasciencecentral.com/profiles/blogs/random-forests-explained-intuitively)  
[Explanation/Demonstration of Gradient Boosting](https://arogozhnikov.github.io/2016/06/24/gradient_boosting_explained.html)  
[Example of kNN](https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/)  

StandCloud Computing
---
[AWS](https://aws.amazon.com/cn/), [Google Cloud](https://cloud.google.com/), [Microsoft Azure](https://azure.microsoft.com/zh-cn/)  

AWS spot option
---
[Overview of Spot mechanism](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-spot-instances.html)
[Spot Setup Guide](https://datasciencebowl.com/aws_guide/)  

Stack and packages
---
[Basic SciPy stack (ipython, numpy, pandas, matplotlib)](https://www.scipy.org/)  
[Jupyter Notebook](https://jupyter.org/)  
[Stand-alone python tSNE package](https://github.com/danielfrg/tsne)  
Libraries to work with sparse CTR-like data: [LibFM](http://www.libfm.org/), [LibFFM]()  
Another tree-based method: RGF ([implemetation](https://github.com/baidu/fast_rgf), [paper](https://arxiv.org/pdf/1109.0887.pdf))  
Python distribution with all-included packages: [Anaconda](https://www.continuum.io/what-is-anaconda)  
[Blog "datas-frame" (contains posts about effective Pandas usage)](https://tomaugspurger.github.io/)  

特征预处理
---
* 数字特征  
* 类别和顺序特征  
* 时间和坐标特征  
* 缺失值  

Order statistic
---
Wikipedia:https://en.wikipedia.org/wiki/Order_statistic  
Scipy:https://docs.scipy.org/doc/scipy-0.16.1/reference/generated/scipy.stats.mstats.rankdata.html

Feature preprocessing
---
[Preprocessing in Sklearn](http://scikit-learn.org/stable/modules/preprocessing.html)  
[Andrew NG about gradient descent and feature scaling](https://www.coursera.org/learn/machine-learning)  
[Feature Scaling and the effect of standardization for machine learning algorithms](http://sebastianraschka.com/Articles/2014_about_feature_scaling.html)    

Feature Important
---
MARS, Random Forest and Gradient Boosted Machines  

Feature generation
---
[Discover Feature Engineering, How to Engineer Features and How to Get Good at It](https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/)  
[Discussion of feature engineering on Quora](https://www.quora.com/What-are-some-best-practices-in-Feature-Engineering)  

Feature extraction
---
* PCA
* Unsupervised clustering methods

Feature selection
---
* [Stepwise regression](https://www.cnblogs.com/sumuncle/p/5647722.html)
* [An Introduction to Feature Selection](https://machinelearningmastery.com/an-introduction-to-feature-selection/)
* Regularization methods LASSO
* [Feature Selection to Improve Accuracy and Decrease Training Time](https://machinelearningmastery.com/feature-selection-to-improve-accuracy-and-decrease-training-time/)
* [Feature Selection in Python with Scikit-Learn](https://machinelearningmastery.com/feature-selection-in-python-with-scikit-learn/)

Feature extraction from text
---
### Bag of words
* [Feature extraction from text with Sklearn](http://scikit-learn.org/stable/modules/feature_extraction.html)
* [More examples of using Sklearn](https://andhint.github.io/machine-learning/nlp/Feature-Extraction-From-Text/) 

### Word2vec
* [Tutorial to Word2vec](https://www.tensorflow.org/tutorials/word2vec)  
* [Tutorial to word2vec usage](https://rare-technologies.com/word2vec-tutorial/)  
* [Text Classification With Word2Vec](https://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/)  
* [Introduction to Word Embedding Models with Word2Vec](https://taylorwhitten.github.io/blog/word2vec)  

### NLP Libraries
* [NLTK](http://www.nltk.org/)  
* [TextBlob](https://github.com/sloria/TextBlob)  

Feature extraction from images
---
### Pretrained models
* [Using pretrained models in Keras](https://keras.io/applications/)
* [Image classification with a pre-trained deep neural network](https://www.kernix.com/blog/image-classification-with-a-pre-trained-deep-neural-network_p11)

### Finetuning
* [How to Retrain Inception's Final Layer for New Categories in Tensorflow](https://www.tensorflow.org/tutorials/image_retraining)
* [Fine-tuning Deep Learning Models in Keras](https://www.tensorflow.org/tutorials/image_retraining)
